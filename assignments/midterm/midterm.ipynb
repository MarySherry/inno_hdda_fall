{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacka (midterm) thon \n",
    "\n",
    "## Detecting Malicious URLs \n",
    "\n",
    "Today you are invited to repeat the path of researchers Detecting Malicious URLs.\n",
    "An anonymized 120-day subset of our ICML-09 data set.\n",
    "The data set consists of about 2.4 million URLs (examples) and 3.2 million features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Download data using link below\n",
    "[Download Dataset](http://www.sysnet.ucsd.edu/projects/url/url_svmlight.tar.gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Description of Data (SVM-light)\n",
    "Uncompressing the archive url_svmlight.tar.gz will yield a directory url_svmlight/ containing the following files:\n",
    "\n",
    "1. **FeatureTypes**. A text file list of feature indices that correspond to real-valued features.\n",
    "2. **DayX.svm** (where X is an integer from 0 to 120) --- The data for day X in SVM-light format. A label of +1 corresponds to a malicious URL and -1 corresponds to a benign URL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Read article\n",
    "Please familiarize yourself with original research article. It will give you required context.\n",
    "\n",
    "*\"**Beyond Blacklists: Learning to Detect Malicious Web Sites from Suspicious URLs**\"* \n",
    "\n",
    "*Justin Ma, Lawrence K. Saul, Stefan Savage, Geoffrey M. Voelker* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 121 files\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "files = glob.glob('./url_svmlight/*.svm')\n",
    "print(\"There are %d files\" % len(files))\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What is inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting url_svmlight,f size 0\n",
      "extracting url_svmlight/Day33.svm,f size 18674876\n",
      "extracting url_svmlight/Day32.svm,f size 18599211\n",
      "extracting url_svmlight/Day53.svm,f size 18963938\n",
      "extracting url_svmlight/Day20.svm,f size 18633460\n",
      "extracting url_svmlight/Day7.svm,f size 18777054\n",
      "extracting url_svmlight/Day117.svm,f size 18106370\n",
      "max X = 3231952, max y dimension = 20000\n"
     ]
    }
   ],
   "source": [
    "uri = ('./url_svmlight.tar.gz')\n",
    "tar = tarfile.open(uri, \"r:gz\")\n",
    "max_obs = 0\n",
    "max_vars = 0\n",
    "i = 0\n",
    "split = 5\n",
    "for tarinfo in tar:\n",
    "    print(\"extracting %s,f size %s\" % (tarinfo.name, tarinfo.size))\n",
    "    if tarinfo.isfile():\n",
    "        f = tar.extractfile(tarinfo.name)\n",
    "        X,y = load_svmlight_file(f)\n",
    "        max_vars = np.maximum(max_vars, X.shape[0])\n",
    "        max_obs = np.maximum(max_obs, X.shape[1])\n",
    "    if i > split:\n",
    "        break\n",
    "    i+=1\n",
    "print(\"max X = %s, max y dimension = %s\" % (max_obs, max_vars)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What is inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.97      0.99      0.98     13979\n",
      "          1       0.98      0.93      0.95      6021\n",
      "\n",
      "avg / total       0.97      0.97      0.97     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "classes = [-1,1] # 1_:url- safety, -1: url- non-safety\n",
    "sgd = SGDClassifier(loss='log')\n",
    "n_features = 3231952\n",
    "split = 5\n",
    "i = 0\n",
    "for tarinfo in tar:\n",
    "    if i > split:\n",
    "        break\n",
    "    if tarinfo.isfile():\n",
    "        f = tar.extractfile(tarinfo.name)\n",
    "        X,y = load_svmlight_file(f,n_features=n_features)\n",
    "        if i < split:\n",
    "            sgd.partial_fit(X,y, classes = classes)\n",
    "        if i == split:\n",
    "            print (classification_report(sgd.predict(X),y))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midterm (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading criteria\n",
    "- Complete solution - 50%\n",
    "- F1 Score - 40%\n",
    "    - The first champion champion get 40%\n",
    "    - Worst champion get 20%\n",
    "    - All others are on a scale between them\n",
    "- Code Style - 10%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deadline\n",
    "9:00 AM MSK Monday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Train, test\n",
    "- Upload data (you can use template above)\n",
    "- Separate your dataset into train and test subsets of observations\n",
    "- Use the 8:2 ratio: 80% train set, 20% test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Find out whether it is possible to reduce the dimension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Get the quality\n",
    "- precision\n",
    "- recall\n",
    "- f1-score\n",
    "- support "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
