{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDDA. Lab6. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete linkage is one implementation of hierarchical agglomerative clustering. The principle of hierarchical agglomerative clustering is to start with a singleton cluster, and clusters are iteratively merged until one single cluster remains. This results in a \"cluster tree,\" which is also called dendrogram. The opposite approach -- starting with one cluster and divide into clusters until only singleton clusters remain - is called divisive hierarchical clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algo:**\n",
    "\n",
    "- Compute a distance or similarity matrix.\n",
    "- Each data point is represented as a singleton cluster.\n",
    "- Repeat\n",
    "    - Merge two closest clusters (e.g., based on distance between most similar or dissimilar members).\n",
    "    - Update the distance (or similarity) matrix.\n",
    "- Until one single cluster remains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The single linkage* algorithm compares the two most similar members instead of the most dissimilar ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Complete linkage* compares the most dissimilar members between clusters in each iteration. The two clusters which have the most similar dissimilar members are merged into a new cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "variables = ['X', 'Y', 'Z']\n",
    "labels = ['ID_0','ID_1','ID_2','ID_3','ID_4']\n",
    "\n",
    "X = np.random.random_sample([5,3])*10\n",
    "df = pd.DataFrame(X, columns=variables, index=labels)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we calculate the pair-wise distances for every row (i.e, between every sample across the different variables). We will use the default euclidean distance measure. \n",
    " In addition, we use the squareform function to return a symmetrical matrix of the pair-wise distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist,squareform\n",
    "\n",
    "row_dist = pd.DataFrame(squareform(pdist(df, metric='euclidean')), columns=labels, index=labels)\n",
    "row_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Squareform distance matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we apply the complete linkage agglomeration to our clusters, the linkage function returns a so-called linkage matrix. This linkage matrix consists of several rows where each row consists of 1 merge. The first and second column denote the most dissimilar members in each cluster, and the third row reports the distance between those members. The last column returns the count of members in the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "row_clusters = linkage(row_dist, method='complete', metric='euclidean')\n",
    "pd.DataFrame(row_clusters, \n",
    "             columns=['row label 1', 'row label 2', 'distance', 'no. of items in clust.'],\n",
    "             index=['cluster %d' %(i+1) for i in range(row_clusters.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condensed distance matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we can either pass a condensed distance matrix (upper triangular) from the pdist function, or we can pass the \"original\" data array and define the 'euclidean' metric as function argument in linkage. However, we shouldn't pass the squareform distance metrics, which would yield incorrect distance values although the overall clustering could be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_clusters = linkage(pdist(df, metric='euclidean'), method='complete')\n",
    "pd.DataFrame(row_clusters, \n",
    "             columns=['row label 1', 'row label 2', 'distance', 'no. of items in clust.'],\n",
    "             index=['cluster %d' %(i+1) for i in range(row_clusters.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input sample matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_clusters = linkage(df.values, method='complete', metric='euclidean')\n",
    "pd.DataFrame(row_clusters, \n",
    "             columns=['row label 1', 'row label 2', 'distance', 'no. of items in clust.'],\n",
    "             index=['cluster %d' %(i+1) for i in range(row_clusters.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "row_dendr = dendrogram(row_clusters, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(df, interpolation='nearest', cmap='hot_r')\n",
    "fig.colorbar(cax)\n",
    "\n",
    "ax.set_xticklabels([''] + list(df.columns))\n",
    "ax.set_yticklabels([''] + list(df.index))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "# makes dendrogram black (1)\n",
    "hierarchy.set_link_color_palette(['black'])\n",
    "\n",
    "# plot row dendrogram\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "axd = fig.add_axes([0.09,0.1,0.2,0.6])\n",
    "row_dendr = dendrogram(row_clusters, orientation='left', \n",
    "                   color_threshold=np.inf, ) # makes dendrogram black (2))\n",
    "\n",
    "# reorder data with respect to clustering\n",
    "df_rowclust = df.ix[row_dendr['leaves'][::-1]]\n",
    "\n",
    "axd.set_xticks([])\n",
    "axd.set_yticks([])\n",
    "\n",
    "\n",
    "# remove axes spines from dendrogram\n",
    "for i in axd.spines.values():\n",
    "        i.set_visible(False)\n",
    "\n",
    "# reorder rows with respect to the clustering\n",
    "df_rowclust = df.ix[row_dendr['leaves'][::-1]]\n",
    "        \n",
    "# plot heatmap\n",
    "axm = fig.add_axes([0.26,0.1,0.6,0.6]) # x-pos, y-pos, width, height\n",
    "cax = axm.matshow(df_rowclust, interpolation='nearest', cmap='hot_r')\n",
    "fig.colorbar(cax)\n",
    "axm.set_xticklabels([''] + list(df_rowclust.columns))\n",
    "axm.set_yticklabels([''] + list(df_rowclust.index))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from numpy.random import RandomState\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "np.random.seed(0)\n",
    "centers = [[1, 1], [-1, -1]]\n",
    "n_clusters = len(centers)\n",
    "X, labels_true = make_blobs(n_samples=3000, \n",
    "                            centers=centers, \n",
    "                            cluster_std=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_data(X, c=[1]*X.shape[0], mu=None):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    if len(np.unique(c)) == 1:\n",
    "        ax.plot(X[:,0], X[:,1], 'o')\n",
    "    else:\n",
    "        ix = np.where(c==1)\n",
    "        ax.plot(X[ix,0], X[ix,1], 'o', \n",
    "                markerfacecolor='red')\n",
    "        ax.plot(mu[0,0], mu[0,1], 'o', \n",
    "                markerfacecolor='red', \n",
    "                markersize=12)\n",
    "        ix = np.where(c==0)\n",
    "        ax.plot(X[ix,0], X[ix,1], 'o', \n",
    "                markerfacecolor='green')\n",
    "        ax.plot(mu[1,0], mu[1,1], 'o', \n",
    "                markerfacecolor='green', \n",
    "                markersize=12)\n",
    "    if not mu is None:\n",
    "        ax.plot(mu[0,0], mu[0,1], 'o', \n",
    "                markerfacecolor='red', \n",
    "                markersize=12)\n",
    "        ax.plot(mu[1,0], mu[1,1], 'o', \n",
    "                markerfacecolor='green', \n",
    "                markersize=12)        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clst = KMeans(n_clusters=2, random_state=2342)\n",
    "clst.fit(X)\n",
    "mu = clst.cluster_centers_\n",
    "plot_cluster_data(X, mu = mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_labels(X, mu):\n",
    "    c = np.argmax(np.c_[np.sum(np.power(X - mu[0,:], 2), axis=1), \n",
    "                        np.sum(np.power(X - mu[1,:], 2), axis=1)], \n",
    "                  axis=1)\n",
    "    return c\n",
    "\n",
    "def update_cluster_centers(X, c):\n",
    "    ix = np.where(c==1)\n",
    "    mu[0,:] = np.mean(X[ix,:], axis=1)\n",
    "    ix = np.where(c==0)\n",
    "    mu[1,:] = np.mean(X[ix,:], axis=1)\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "mu = np.array([[2.0,-1.0], [-2.0,1.0]])\n",
    "plot_cluster_data(X, mu=mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 2\n",
    "for it in range(niter):\n",
    "    print('Iteration ' + str(it) + ':')\n",
    "    c = update_labels(X, mu)\n",
    "    print('...updating labels:')\n",
    "    plot_cluster_data(X, c=c, mu=mu)\n",
    "    print('...updating centers:')    \n",
    "    mu = update_cluster_centers(X, c)\n",
    "    plot_cluster_data(X, mu=mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from numpy.random import RandomState\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points, labels = datasets.make_moons(n_samples=100, noise=.05)\n",
    "palette = np.array(sns.color_palette(\"hls\", 8))\n",
    "plt.scatter(*points.T, color=palette[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moons = KMeans(n_clusters=2, random_state=RandomState(42))\n",
    "moons.fit(points)\n",
    "plt.scatter(*points.T, color=palette[moons.labels_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a density-based clustering algorithm, introduced [Ester et al. (1996)](https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf).\n",
    "\n",
    "DBSCAN infers the number of clusters from the dataset, allowing it to discover clusters of arbitrary shape. It establishes a **neighborhood size**, and assigns points to categories based on their relationship to other points, conditioned on this neighborhood size. \n",
    "\n",
    "This confers several advantages:\n",
    "\n",
    "- Allows for more complex cluster shapes\n",
    "- K does not need to be specified\n",
    "- Automatically finds outliers\n",
    "\n",
    "While we don't need to choose K, we do need to select a distance function for quantifying **dissimilarity** between points.\n",
    "\n",
    "\n",
    "\n",
    "2. Connect core points into clusters\n",
    "\n",
    "3. Assign boundary points to clusters\n",
    "\n",
    "The steps to the DBSCAN algorithm are:\n",
    "\n",
    "1. **Determine the type of a new point**\n",
    "\n",
    "    - core\n",
    "    - boundary\n",
    "    - outlier\n",
    "\n",
    "  We randomly pick that has not yet been assigned to a cluster, or been designated as an outlier. For this point, we determine its neighborhood. If it is a **core point**, we seed a cluster around it, otherwise label the point as an **outlier**.\n",
    "\n",
    "2. **Expand the new cluster by adding all reachable points**. Once we find a core point (and hence, a cluster), find all points that are reachable based in the neighborhood and add them to the cluster. If a point previously found to be an outlier is included, change its status to a **border point**.\n",
    "\n",
    "3. Repeat these steps until all points are either assigned to a cluster or designated as an outlier.\n",
    "\n",
    "The `DBSCAN` class in `scikit-learn` is a straightforward implementation of this algorithm, and requires three main arguments:\n",
    "\n",
    "- `eps` defines the size of the neighborhood around each point\n",
    "\n",
    "- `min_samples` is the number of points that needs to be within the neigborhood for a point to be considered a core point; density level threshold\n",
    "\n",
    "- `metric` is either a callable function or a string corresponding to a built-in distance metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan_moons = DBSCAN(eps=0.4, min_samples=11)\n",
    "dbscan_moons.fit(points)\n",
    "dbscan_moons.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*points.T, color=palette[dbscan_moons.labels_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "n_samples = 1000\n",
    "X1 = 2.0*np.random.randn(n_samples, 2) + np.array([5, 3])\n",
    "C = np.array([[0., -0.5], [3.5, .7]])\n",
    "X2 = np.dot(np.random.randn(n_samples, 2), C)\n",
    "X_train = np.vstack([X1, X2])\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(X_train[:,0], X_train[:,1], 'o')\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "model = GMM(n_components=2, covariance_type='full')\n",
    "model.fit(X_train)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(X_train[:,0], X_train[:,1], 'o', alpha=.1, ms=5)\n",
    "\n",
    "for i in range(2):    \n",
    "    mu = model.means_[i]\n",
    "    sigma = model.covars_[i]\n",
    "    sigma_inv = np.linalg.inv(sigma)\n",
    "    sigma_det = np.linalg.det(sigma)\n",
    "    x = np.linspace(-15.0, 15.0)\n",
    "    y = np.linspace(-4.0, 10.0)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "    XX = np.dot(np.dot(XX - mu, sigma_inv), \n",
    "                np.transpose(XX - mu))\n",
    "    P = np.exp(-0.5*np.diagonal(XX))/(2*np.pi*sigma_det**0.5)\n",
    "    P = P.reshape(X.shape)\n",
    "    CS = plt.contour(X, Y, P)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Estep(mu, sigma, phi):\n",
    "    # calculate determinants of sigma's\n",
    "    det_sigma = np.array([[np.linalg.det(sigma[i])] \n",
    "                          for i in range(k)])\n",
    "    # calculate inverse matrices for sigma's\n",
    "    inv_sigma = np.array([np.linalg.inv(sigma[i]) \n",
    "                          for i in range(k)]).reshape(sigma.shape)\n",
    "    # calculate Q(z) = p(x|z)*p(z)/p(x)\n",
    "    pxz = np.array([\n",
    "            np.exp(\n",
    "                -0.5*np.diagonal(\n",
    "                    np.dot(\n",
    "                        np.dot(X_train - mu[i,:], inv_sigma[i]), \n",
    "                        np.transpose(X_train - mu[i,:])\n",
    "                    )\n",
    "                )\n",
    "            )/((2.0*np.pi)**(n/2.0)*det_sigma[i,0]**0.5)*phi[i,0] \n",
    "            for i in range(k)]).T\n",
    "    pz = pxz/np.sum(pxz, axis=1).reshape((-1, 1))\n",
    "    return pz\n",
    "\n",
    "def Mstep(pz):\n",
    "    pz_sum = np.sum(pz, axis=0).reshape((-1,1))\n",
    "    # update parameters\n",
    "    phi_new = pz_sum/m\n",
    "    mu_new = np.transpose(np.dot(X_train.T, pz)/pz_sum.T)\n",
    "    sigma_new = np.array([\n",
    "            np.dot(np.array([\n",
    "                        np.outer(X_train[j,:] - mu_new[i,:], \n",
    "                                 X_train[j,:] - mu_new[i,:]) \n",
    "                        for j in range(m)]).reshape((m, -1)).T, \n",
    "                   pz[:,i]).reshape((n,n))/pz_sum[i,0] \n",
    "            for i in range(k)]).reshape((k,n,n))\n",
    "    return mu_new, sigma_new, phi_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(X_train[:,0], X_train[:,1], 'o')\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# number of components\n",
    "k = 2\n",
    "# number of features\n",
    "n = X_train.shape[1]\n",
    "# number of training examples\n",
    "m = X_train.shape[0]\n",
    "# number of iterations\n",
    "niter = 10\n",
    "# initial values of phi\n",
    "phi = np.array([1.0/k]*k).reshape((k,-1))\n",
    "# initial values for mu and sigma\n",
    "mu = []\n",
    "sigma = []\n",
    "np.random.seed(234)\n",
    "for cl in range(k):\n",
    "    mu.append(np.mean(X_train[np.random.choice(int(m), int(m/2)),:], axis=0))\n",
    "    sigma.append(np.identity(n))\n",
    "mu = np.array(mu).reshape((k, n))\n",
    "sigma = np.array(sigma).reshape((k, n, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nit in range(niter):\n",
    "    print('Iteration ' + str(nit+1) + ':')\n",
    "    pz = Estep(mu, sigma, phi)\n",
    "    mu, sigma, phi = Mstep(pz)\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(X_train[:,0], X_train[:,1], 'o', alpha=.1, ms=5)\n",
    "    for i in range(k):    \n",
    "        mu_i = mu[i,:]\n",
    "        sigma_i = sigma[i]\n",
    "        sigma_i_inv = np.linalg.inv(sigma_i)\n",
    "        x = np.linspace(-15.0, 15.0)\n",
    "        y = np.linspace(-4.0, 10.0)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "        P = np.exp(-0.5*np.diagonal(\n",
    "                np.dot(\n",
    "                    np.dot(XX - mu_i, sigma_i_inv), \n",
    "                    np.transpose(XX - mu_i)\n",
    "                )))/(2*np.pi*np.linalg.det(sigma_i)**0.5)\n",
    "        P = P.reshape(X.shape)\n",
    "        CS = plt.contour(X, Y, P)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.externals import six\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "plotly.offline.init_notebook_mode()\n",
    "\n",
    "def rename_columns(df, prefix='x'):\n",
    "    \"\"\"\n",
    "    Rename the columns of a dataframe to have X in front of them\n",
    "\n",
    "    :param df: data frame we're operating on\n",
    "    :param prefix: the prefix string\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df.columns = [prefix + str(i) for i in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_classification(n_samples=100, n_classes=3, n_features=3, n_redundant=0, n_informative=3,\n",
    "                             scale=1000, n_clusters_per_class=1)\n",
    "df = pd.DataFrame(X)\n",
    "# rename X columns\n",
    "df = rename_columns(df)\n",
    "# and add the Y\n",
    "df['y'] = Y\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster1=df.loc[df['y'] == 0]\n",
    "cluster2=df.loc[df['y'] == 1]\n",
    "cluster3=df.loc[df['y'] == 2]\n",
    "\n",
    "scatter1 = dict(\n",
    "    mode = \"markers\",\n",
    "    name = \"Cluster 1\",\n",
    "    type = \"scatter3d\",    \n",
    "    x = cluster1.as_matrix()[:,0], y = cluster1.as_matrix()[:,1], z = cluster1.as_matrix()[:,2],\n",
    "    marker = dict( size=2, color='green')\n",
    ")\n",
    "scatter2 = dict(\n",
    "    mode = \"markers\",\n",
    "    name = \"Cluster 2\",\n",
    "    type = \"scatter3d\",    \n",
    "    x = cluster2.as_matrix()[:,0], y = cluster2.as_matrix()[:,1], z = cluster2.as_matrix()[:,2],\n",
    "    marker = dict( size=2, color='blue')\n",
    ")\n",
    "scatter3 = dict(\n",
    "    mode = \"markers\",\n",
    "    name = \"Cluster 3\",\n",
    "    type = \"scatter3d\",    \n",
    "    x = cluster3.as_matrix()[:,0], y = cluster3.as_matrix()[:,1], z = cluster3.as_matrix()[:,2],\n",
    "    marker = dict( size=2, color='red')\n",
    ")\n",
    "cluster1 = dict(\n",
    "    alphahull = 5,\n",
    "    name = \"Cluster 1\",\n",
    "    opacity = .1,\n",
    "    type = \"mesh3d\",    \n",
    "    x = cluster1.as_matrix()[:,0], y = cluster1.as_matrix()[:,1], z = cluster1.as_matrix()[:,2],\n",
    "    color='green', showscale = True\n",
    ")\n",
    "cluster2 = dict(\n",
    "    alphahull = 5,\n",
    "    name = \"Cluster 2\",\n",
    "    opacity = .1,\n",
    "    type = \"mesh3d\",    \n",
    "    x = cluster2.as_matrix()[:,0], y = cluster2.as_matrix()[:,1], z = cluster2.as_matrix()[:,2],\n",
    "    color='blue', showscale = True\n",
    ")\n",
    "cluster3 = dict(\n",
    "    alphahull = 5,\n",
    "    name = \"Cluster 3\",\n",
    "    opacity = .1,\n",
    "    type = \"mesh3d\",    \n",
    "    x = cluster3.as_matrix()[:,0], y = cluster3.as_matrix()[:,1], z = cluster3.as_matrix()[:,2],\n",
    "    color='red', showscale = True\n",
    ")\n",
    "layout = dict(\n",
    "    title = 'Interactive Cluster Shapes in 3D',\n",
    "    scene = dict(\n",
    "        xaxis = dict( zeroline=True ),\n",
    "        yaxis = dict( zeroline=True ),\n",
    "        zaxis = dict( zeroline=True ),\n",
    "    )\n",
    ")\n",
    "fig = dict( data=[scatter1, scatter2, scatter3, cluster1, cluster2, cluster3], layout=layout )\n",
    "# Use py.iplot() for IPython notebook\n",
    "plotly.offline.iplot(fig, filename='mesh3d_sample')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
